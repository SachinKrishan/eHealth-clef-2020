{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import heapq\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishi/anaconda3/envs/tensorflow1.1/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/rishi/anaconda3/envs/tensorflow1.1/lib/python3.7/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "devD_df = pd.read_csv('dev/devD.tsv', delimiter='\\t', header=None)\n",
    "trainD_df = pd.read_csv('train/trainD.tsv', delimiter='\\t', header=None)\n",
    "\n",
    "# applying groupby() function to \n",
    "# group the data on team value. \n",
    "tD_gk = trainD_df.groupby([0]) \n",
    "  \n",
    "# Let's print the first entries \n",
    "# in all the groups formed. \n",
    "tD_gk.first()\n",
    "\n",
    "trainD_df = tD_gk.aggregate(lambda x: tuple(x))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "trainD_enc = pd.DataFrame(mlb.fit_transform(trainD_df[1]),\n",
    "                   columns= mlb.classes_, \n",
    "                   index= trainD_df.index).max(level=0)\n",
    "\n",
    "trainD_enc['file'] = \"\"\n",
    "for i in range(trainD_enc.shape[0]):\n",
    "    f = open(\"train/text_files_en/\"+ trainD_enc.index[i] + \".txt\", \"r\")\n",
    "    trainD_enc['file'][i] = f.read()\n",
    "    \n",
    "# applying groupby() function to \n",
    "# group the data on team value. \n",
    "tD_gk = devD_df.groupby([0]) \n",
    "  \n",
    "# Let's print the first entries \n",
    "# in all the groups formed. \n",
    "tD_gk.first()\n",
    "\n",
    "devD_df = tD_gk.aggregate(lambda x: tuple(x))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "devD_enc = pd.DataFrame(mlb.fit_transform(devD_df[1]),\n",
    "                   columns= mlb.classes_, \n",
    "                   index= devD_df.index).max(level=0)\n",
    "\n",
    "devD_enc['file'] = \"\"\n",
    "for i in range(devD_enc.shape[0]):\n",
    "    f = open(\"dev/text_files_en/\"+ devD_enc.index[i] + \".txt\", \"r\")\n",
    "    devD_enc['file'][i] = f.read()\n",
    "    \n",
    "columns_train = trainD_enc.columns\n",
    "columns_dev = devD_enc.columns\n",
    "\n",
    "count = 0\n",
    "for x in columns_dev:\n",
    "    if x not in columns_train:\n",
    "        trainD_enc[x] = 0\n",
    "        \n",
    "count = 0\n",
    "for x in columns_train:\n",
    "    if x not in columns_dev:\n",
    "        devD_enc[x] = 0 \n",
    "        \n",
    "train = trainD_enc['file']\n",
    "train = pd.DataFrame(train)\n",
    "\n",
    "del trainD_enc['file']\n",
    "\n",
    "train['tar'] = trainD_enc.values.tolist()\n",
    "\n",
    "dev = devD_enc['file']\n",
    "dev = pd.DataFrame(dev)\n",
    "\n",
    "del devD_enc['file']\n",
    "\n",
    "dev['tar'] = devD_enc.values.tolist()\n",
    "\n",
    "train = pd.concat([train, dev.iloc[:200]])\n",
    "\n",
    "dev = dev.iloc[200:]\n",
    "\n",
    "train = train.reset_index()\n",
    "#dev = dev.reset_index()\n",
    "\n",
    "del train[0]\n",
    "#del dev[0]\n",
    "\n",
    "train = train.rename(columns={\"file\": \"text\", \"tar\": \"labels\"})\n",
    "dev = dev.rename(columns={\"file\": \"text\", \"tar\": \"labels\", 0:'index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = \" \".join([lemmatizer.lemmatize(i) for i in text])\n",
    "    return lem_text\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def word_stemmer(text):\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in text])\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(lambda x: remove_punctuation(x), 1)\n",
    "train['text'] = train['text'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "train['text'] = train['text'].apply(lambda x: remove_stopwords(x))\n",
    "train['text'] = train['text'].apply(lambda x: word_lemmatizer(x))\n",
    "#train['text'] = train['text'].apply(lambda x: word_stemmer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(df, leng, overlap):               # leng is excluding the overlap\n",
    "    new_df = pd.DataFrame(columns=df.columns)         # new df with same coulmns\n",
    "    row = 0\n",
    "    for i in range(df.shape[0]):                      # loop through df rows\n",
    "        words = df['text'].loc[i].split()\n",
    "        count = 0\n",
    "        for j in range(math.ceil(len(words)/leng)):   #loop through sentence\n",
    "            new_df.loc[row] = df.loc[i]\n",
    "            new_df['text'].loc[row] = \"\"\n",
    "            for k in range (leng + overlap):\n",
    "                if(j*leng+k < len(words)):\n",
    "                    new_df['text'].loc[row] += words[j*leng + k] + \" \"\n",
    "            row += 1\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>describe case 37yearold man previous active li...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neurological examination revealed meningeal si...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transthoracic echocardiography show significan...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report case 29yearold woman underwent pelvic u...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cytoplasm well nucleus slightly eosinophilic m...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>blood vitreous humor pericardial fluid pleural...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>n meningitidis serogroup c watersenhouse syndr...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>73yearold woman came emergency department acci...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>condition joint stable varus valgus extension ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>knee descending stair compatible patellofemora...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1668 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     describe case 37yearold man previous active li...   \n",
       "1     neurological examination revealed meningeal si...   \n",
       "2     transthoracic echocardiography show significan...   \n",
       "3     report case 29yearold woman underwent pelvic u...   \n",
       "4     cytoplasm well nucleus slightly eosinophilic m...   \n",
       "...                                                 ...   \n",
       "1663  blood vitreous humor pericardial fluid pleural...   \n",
       "1664  n meningitidis serogroup c watersenhouse syndr...   \n",
       "1665  73yearold woman came emergency department acci...   \n",
       "1666  condition joint stable varus valgus extension ...   \n",
       "1667  knee descending stair compatible patellofemora...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "1663  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "1664  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "1665  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1666  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1667  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[1668 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = split_sentences(train, 100, 10)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [['bert', 'bert-base-uncased'], ['roberta', 'roberta-base-uncased'], ['bert', 'emilyalsentzer/Bio_ClinicalBERT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cf91d68f044fd1b2783b3cd951985d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f52b6efcc04c00abbdbd047efb679c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435778770.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0298882fc141467ea5d6cea5fbf00a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "\n",
    "model = MultiLabelClassificationModel(\n",
    "    \"bert\", # model name (for bert change to \"bert\")\n",
    "    \"emilyalsentzer/Bio_ClinicalBERT\", # pretrained model (for bert change to \"bert-base-uncased\")\n",
    "    num_labels= 2194,\n",
    "    args={\"num_train_epochs\": 10, \"train_batch_size\": 5, \"fp16_opt_level\" : 'O0',\n",
    "    \"gradient_accumulation_steps\": 2, \"overwrite_output_dir\": True,  \"learning_rate\": 4e-5, \"max_seq_length\": 128, \"save_eval_checkpoints\": False, \"save_model_every_epoch\": False},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620757ac81ba4b15a8e40a3635cf6b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1668.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c89d562c094b3a92f6bd9865407d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=10.0, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052ed1cd89334fe8added78dfca3df27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=334.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.092958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debb622847334fd585acb0381106e33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=334.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.038578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fc27daf2d248ab9dadf9f3597da462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=334.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.033976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cba34bcca2b41bcac0692f4e3878bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=334.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.036028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b96bd3c081c4449abdbf25ccf95f4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=334.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.040045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cac2e9bb6140f3a96a00a2e5fcabe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=334.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.020658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1347f5f5656849729cecd74511b98c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=334.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.038576\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ea821579ca4d758d41007228677167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=334.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.045130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ea1daf87cc4b0fbc22cbbfcea1adc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=334.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.034724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96307a69d408442dbd2dafb36e5cdbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=334.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.027510\n",
      "\n",
      "Training of bert model complete. Saved to outputs/.\n"
     ]
    }
   ],
   "source": [
    "model.train_model(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae7baab757a4cb19e3b1d60de49dc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8153f9a4eb4616aac8961d04585516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'LRAP': 0.02148876276917489, 'acc': 0.3250209402326321, 'eval_loss': 0.030885874426790645}\n",
      "[[0.00842041 0.00679542 0.00743072 ... 0.00236768 0.00243979 0.00239703]\n",
      " [0.00841848 0.00679426 0.00742733 ... 0.00236641 0.00243892 0.00239605]\n",
      " [0.00842116 0.00679574 0.00742968 ... 0.00236763 0.00243991 0.00239653]\n",
      " ...\n",
      " [0.00841997 0.0067957  0.00742833 ... 0.0023671  0.00243934 0.00239683]\n",
      " [0.00842177 0.00679657 0.00742897 ... 0.00236743 0.00243921 0.00239699]\n",
      " [0.00841818 0.00679567 0.00742887 ... 0.00236632 0.00243866 0.00239714]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "result, model_outputs, wrong_predictions = model.eval_model(dev, acc=sklearn.metrics.label_ranking_loss)\n",
    "print(result)\n",
    "print(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
